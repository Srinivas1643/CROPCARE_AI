{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "073506ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CropCare AI: Intelligent Disease Detection and Farming Advisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00db3c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Team Member 1 \n",
    "#Srinivasa Reddy Julakanti\n",
    "\n",
    "#Team Member 2\n",
    "#Shaik Mohammed Hamid\n",
    "\n",
    "#Team Member 3\n",
    "#Yashwanth K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81fd6bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb59b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'chilli_dataset'\n",
    "\n",
    "# Define transforms for the training data and testing data\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cf3bd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(train_data.class_to_idx)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4ee2a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cercospora': 0,\n",
       " 'healthy': 1,\n",
       " 'mites_and_thrips': 2,\n",
       " 'nutritional': 3,\n",
       " 'powdery_mildew': 4}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "072f1349",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srini\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\srini\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82eaa864",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "fc = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(512, 500)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(500, 5)),  # Change the number of output units to 3 for 3 classes\n",
    "    ('output', nn.LogSoftmax(dim=1))\n",
    "]))\n",
    "\n",
    "\n",
    "model.fc = fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecb91e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (fc1): Linear(in_features=512, out_features=500, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (fc2): Linear(in_features=500, out_features=5, bias=True)\n",
       "    (output): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60e5df7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if it's available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "from collections import OrderedDict\n",
    "model.fc = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(512, 400)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(400, 5)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Only train the classifier parameters, feature parameters are frozen\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n",
    "\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "229631f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (fc1): Linear(in_features=512, out_features=400, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (fc2): Linear(in_features=400, out_features=5, bias=True)\n",
       "    (output): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f36bd162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10.. Train loss: 2.258.. Test loss: 1.866.. Test accuracy: 0.378\n",
      "tensor([[59.,  1.,  2.,  0.,  0.],\n",
      "        [22.,  8., 20.,  0.,  0.],\n",
      "        [15.,  4., 42.,  0.,  0.],\n",
      "        [40.,  4., 11.,  0.,  0.],\n",
      "        [45.,  5.,  2.,  0.,  0.]])\n",
      "Epoch 1/10.. Train loss: 1.693.. Test loss: 1.476.. Test accuracy: 0.354\n",
      "tensor([[41.,  0.,  0.,  1., 20.],\n",
      "        [ 1.,  0.,  0.,  0., 49.],\n",
      "        [ 3.,  0.,  0.,  1., 57.],\n",
      "        [31.,  0.,  0.,  1., 23.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 1/10.. Train loss: 1.447.. Test loss: 1.263.. Test accuracy: 0.572\n",
      "tensor([[15.,  0.,  6., 41.,  0.],\n",
      "        [ 0.,  7., 26., 10.,  7.],\n",
      "        [ 0.,  3., 48.,  9.,  1.],\n",
      "        [ 2.,  1., 12., 40.,  0.],\n",
      "        [ 2.,  0.,  1.,  1., 48.]])\n",
      "Epoch 1/10.. Train loss: 1.314.. Test loss: 1.120.. Test accuracy: 0.569\n",
      "tensor([[52.,  5.,  2.,  2.,  1.],\n",
      "        [ 4., 16., 15.,  0., 15.],\n",
      "        [ 3., 17., 34.,  3.,  4.],\n",
      "        [40.,  5.,  7.,  2.,  1.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 1/10.. Train loss: 1.285.. Test loss: 1.086.. Test accuracy: 0.586\n",
      "tensor([[54.,  0.,  8.,  0.,  0.],\n",
      "        [ 4.,  0., 37.,  0.,  9.],\n",
      "        [ 0.,  1., 55.,  3.,  2.],\n",
      "        [39.,  0., 15.,  1.,  0.],\n",
      "        [ 1.,  0.,  0.,  0., 51.]])\n",
      "Epoch 1/10.. Train loss: 1.138.. Test loss: 1.107.. Test accuracy: 0.476\n",
      "tensor([[11.,  0.,  1., 49.,  1.],\n",
      "        [ 0.,  7.,  5., 20., 18.],\n",
      "        [ 0.,  3.,  9., 34., 15.],\n",
      "        [ 1.,  1.,  2., 50.,  1.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 1/10.. Train loss: 1.235.. Test loss: 1.049.. Test accuracy: 0.578\n",
      "tensor([[55.,  0.,  7.,  0.,  0.],\n",
      "        [ 6.,  0., 35.,  0.,  9.],\n",
      "        [ 2.,  1., 53.,  2.,  3.],\n",
      "        [40.,  0., 14.,  1.,  0.],\n",
      "        [ 2.,  0.,  0.,  0., 50.]])\n",
      "Epoch 1/10.. Train loss: 1.280.. Test loss: 1.005.. Test accuracy: 0.573\n",
      "tensor([[50.,  0., 12.,  0.,  0.],\n",
      "        [ 3.,  1., 32.,  0., 14.],\n",
      "        [ 0.,  1., 53.,  3.,  4.],\n",
      "        [35.,  0., 18.,  1.,  1.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 2/10.. Train loss: 1.108.. Test loss: 1.090.. Test accuracy: 0.531\n",
      "tensor([[26.,  1.,  1., 30.,  4.],\n",
      "        [ 0., 11.,  7., 11., 21.],\n",
      "        [ 0.,  7., 11., 20., 23.],\n",
      "        [ 5.,  2.,  2., 45.,  1.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 2/10.. Train loss: 0.980.. Test loss: 1.118.. Test accuracy: 0.557\n",
      "tensor([[34.,  0., 12., 16.,  0.],\n",
      "        [ 1.,  0., 45.,  2.,  2.],\n",
      "        [ 0.,  0., 57.,  3.,  1.],\n",
      "        [13.,  0., 21., 21.,  0.],\n",
      "        [ 0.,  0.,  6.,  3., 43.]])\n",
      "Epoch 2/10.. Train loss: 1.060.. Test loss: 1.089.. Test accuracy: 0.510\n",
      "tensor([[43.,  0.,  9.,  5.,  5.],\n",
      "        [ 3.,  4., 22.,  0., 21.],\n",
      "        [ 0.,  3., 34.,  3., 21.],\n",
      "        [29.,  0., 19.,  6.,  1.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 2/10.. Train loss: 1.101.. Test loss: 0.974.. Test accuracy: 0.594\n",
      "tensor([[41.,  1.,  3., 17.,  0.],\n",
      "        [ 5., 10., 13., 11., 11.],\n",
      "        [ 3.,  3., 36.,  9., 10.],\n",
      "        [27.,  1.,  3., 24.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 2/10.. Train loss: 0.866.. Test loss: 1.105.. Test accuracy: 0.505\n",
      "tensor([[18.,  0.,  2., 42.,  0.],\n",
      "        [ 0.,  1., 17., 24.,  8.],\n",
      "        [ 0.,  0., 22., 29., 10.],\n",
      "        [ 5.,  0.,  3., 47.,  0.],\n",
      "        [ 0.,  0.,  0.,  2., 50.]])\n",
      "Epoch 2/10.. Train loss: 0.943.. Test loss: 0.972.. Test accuracy: 0.609\n",
      "tensor([[43.,  0., 12.,  7.,  0.],\n",
      "        [ 1., 10., 34.,  1.,  4.],\n",
      "        [ 0.,  1., 53.,  3.,  4.],\n",
      "        [21.,  3., 19., 12.,  0.],\n",
      "        [ 0.,  1.,  1.,  0., 50.]])\n",
      "Epoch 2/10.. Train loss: 0.959.. Test loss: 1.074.. Test accuracy: 0.580\n",
      "tensor([[31.,  0.,  4., 27.,  0.],\n",
      "        [ 4.,  0., 22., 16.,  8.],\n",
      "        [ 1.,  0., 35., 13., 12.],\n",
      "        [ 9.,  0.,  5., 41.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 2/10.. Train loss: 0.941.. Test loss: 1.063.. Test accuracy: 0.583\n",
      "tensor([[17.,  1.,  6., 38.,  0.],\n",
      "        [ 0.,  8., 20., 10., 12.],\n",
      "        [ 0.,  1., 39.,  5., 16.],\n",
      "        [ 3.,  1.,  7., 44.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 3/10.. Train loss: 0.904.. Test loss: 1.312.. Test accuracy: 0.484\n",
      "tensor([[58.,  0.,  3.,  0.,  1.],\n",
      "        [20.,  1., 14.,  0., 15.],\n",
      "        [23.,  0., 22.,  3., 13.],\n",
      "        [53.,  0.,  1.,  1.,  0.],\n",
      "        [ 2.,  0.,  0.,  0., 50.]])\n",
      "Epoch 3/10.. Train loss: 1.009.. Test loss: 1.090.. Test accuracy: 0.535\n",
      "tensor([[21.,  1.,  9., 29.,  2.],\n",
      "        [ 0.,  1., 28.,  3., 18.],\n",
      "        [ 0.,  1., 38.,  3., 19.],\n",
      "        [ 3.,  0., 17., 34.,  1.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 3/10.. Train loss: 0.874.. Test loss: 1.086.. Test accuracy: 0.503\n",
      "tensor([[35.,  1.,  1., 25.,  0.],\n",
      "        [11., 12.,  5., 19.,  3.],\n",
      "        [13.,  3., 13., 26.,  6.],\n",
      "        [20.,  1.,  0., 34.,  0.],\n",
      "        [ 4.,  0.,  0.,  3., 45.]])\n",
      "Epoch 3/10.. Train loss: 0.887.. Test loss: 0.976.. Test accuracy: 0.603\n",
      "tensor([[39.,  0.,  7., 15.,  1.],\n",
      "        [ 1.,  7., 26.,  3., 13.],\n",
      "        [ 0.,  1., 41.,  4., 15.],\n",
      "        [17.,  1.,  8., 28.,  1.],\n",
      "        [ 0.,  0.,  1.,  0., 51.]])\n",
      "Epoch 3/10.. Train loss: 0.769.. Test loss: 1.192.. Test accuracy: 0.549\n",
      "tensor([[34.,  1.,  3., 18.,  6.],\n",
      "        [ 3.,  7., 15.,  2., 23.],\n",
      "        [ 0.,  2., 25.,  3., 31.],\n",
      "        [15.,  1.,  4., 32.,  3.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 3/10.. Train loss: 0.837.. Test loss: 0.972.. Test accuracy: 0.604\n",
      "tensor([[39.,  1.,  5., 16.,  1.],\n",
      "        [ 3., 10., 16.,  5., 16.],\n",
      "        [ 0.,  2., 36.,  5., 18.],\n",
      "        [19.,  1.,  6., 29.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 3/10.. Train loss: 0.919.. Test loss: 1.017.. Test accuracy: 0.576\n",
      "tensor([[48.,  0.,  8.,  6.,  0.],\n",
      "        [ 3.,  2., 39.,  2.,  4.],\n",
      "        [ 0.,  1., 52.,  3.,  5.],\n",
      "        [29.,  0., 13., 13.,  0.],\n",
      "        [ 0.,  0.,  7.,  0., 45.]])\n",
      "Epoch 3/10.. Train loss: 0.958.. Test loss: 1.395.. Test accuracy: 0.493\n",
      "tensor([[16.,  0.,  2., 40.,  4.],\n",
      "        [ 0.,  3., 11., 12., 24.],\n",
      "        [ 1.,  0., 16., 14., 30.],\n",
      "        [ 4.,  0.,  2., 47.,  2.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 3/10.. Train loss: 0.973.. Test loss: 1.129.. Test accuracy: 0.538\n",
      "tensor([[19.,  2.,  7., 31.,  3.],\n",
      "        [ 0.,  6., 21.,  4., 19.],\n",
      "        [ 0.,  1., 35.,  4., 21.],\n",
      "        [ 3.,  3., 13., 35.,  1.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 4/10.. Train loss: 0.899.. Test loss: 1.275.. Test accuracy: 0.493\n",
      "tensor([[56.,  0.,  2.,  4.,  0.],\n",
      "        [27.,  1.,  7., 13.,  2.],\n",
      "        [31.,  0., 22.,  4.,  4.],\n",
      "        [38.,  0.,  0., 17.,  0.],\n",
      "        [11.,  0.,  0.,  0., 41.]])\n",
      "Epoch 4/10.. Train loss: 0.962.. Test loss: 1.179.. Test accuracy: 0.538\n",
      "tensor([[28.,  2.,  4., 25.,  3.],\n",
      "        [ 1.,  5., 19.,  2., 23.],\n",
      "        [ 0.,  4., 25.,  5., 27.],\n",
      "        [ 6.,  2.,  8., 37.,  2.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 4/10.. Train loss: 0.865.. Test loss: 1.096.. Test accuracy: 0.583\n",
      "tensor([[28.,  0.,  4., 29.,  1.],\n",
      "        [ 2.,  6., 17., 11., 14.],\n",
      "        [ 1.,  0., 34.,  7., 19.],\n",
      "        [ 7.,  1.,  6., 40.,  1.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 4/10.. Train loss: 0.918.. Test loss: 1.067.. Test accuracy: 0.566\n",
      "tensor([[57.,  0.,  2.,  3.,  0.],\n",
      "        [22.,  7., 13.,  3.,  5.],\n",
      "        [19.,  0., 34.,  3.,  5.],\n",
      "        [40.,  0.,  1., 14.,  0.],\n",
      "        [ 7.,  0.,  0.,  0., 45.]])\n",
      "Epoch 4/10.. Train loss: 0.739.. Test loss: 1.011.. Test accuracy: 0.580\n",
      "tensor([[37.,  3.,  3., 18.,  1.],\n",
      "        [ 3., 11., 15.,  4., 17.],\n",
      "        [ 1.,  4., 29.,  5., 22.],\n",
      "        [17.,  3.,  3., 30.,  2.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 4/10.. Train loss: 0.812.. Test loss: 1.084.. Test accuracy: 0.566\n",
      "tensor([[33.,  1.,  7., 18.,  3.],\n",
      "        [ 2.,  7., 19.,  4., 18.],\n",
      "        [ 0.,  1., 32.,  3., 25.],\n",
      "        [10.,  4.,  8., 31.,  2.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 4/10.. Train loss: 0.882.. Test loss: 1.019.. Test accuracy: 0.605\n",
      "tensor([[32.,  0.,  4., 26.,  0.],\n",
      "        [ 1., 11., 21., 13.,  4.],\n",
      "        [ 1.,  0., 37.,  9., 14.],\n",
      "        [ 7.,  1.,  5., 42.,  0.],\n",
      "        [ 0.,  2.,  1.,  3., 46.]])\n",
      "Epoch 4/10.. Train loss: 0.832.. Test loss: 1.076.. Test accuracy: 0.565\n",
      "tensor([[46.,  0.,  6., 10.,  0.],\n",
      "        [ 3.,  6., 27.,  2., 12.],\n",
      "        [ 3.,  1., 33.,  3., 21.],\n",
      "        [26.,  2.,  7., 19.,  1.],\n",
      "        [ 1.,  0.,  0.,  0., 51.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10.. Train loss: 0.867.. Test loss: 1.448.. Test accuracy: 0.524\n",
      "tensor([[34.,  0.,  2., 22.,  4.],\n",
      "        [ 6.,  3., 13.,  4., 24.],\n",
      "        [ 3.,  0., 22.,  6., 30.],\n",
      "        [17.,  0.,  3., 32.,  3.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 5/10.. Train loss: 0.775.. Test loss: 1.046.. Test accuracy: 0.589\n",
      "tensor([[28.,  4.,  2., 28.,  0.],\n",
      "        [ 2., 15., 17.,  8.,  8.],\n",
      "        [ 0.,  5., 31.,  6., 19.],\n",
      "        [ 6.,  3.,  5., 41.,  0.],\n",
      "        [ 0.,  4.,  0.,  0., 48.]])\n",
      "Epoch 5/10.. Train loss: 0.726.. Test loss: 1.256.. Test accuracy: 0.535\n",
      "tensor([[35.,  0.,  6., 19.,  2.],\n",
      "        [ 2.,  1., 23.,  3., 21.],\n",
      "        [ 1.,  0., 30.,  5., 25.],\n",
      "        [16.,  1.,  8., 28.,  2.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 5/10.. Train loss: 0.773.. Test loss: 1.170.. Test accuracy: 0.536\n",
      "tensor([[49.,  4.,  1.,  8.,  0.],\n",
      "        [12., 12.,  7.,  4., 15.],\n",
      "        [12.,  4., 17.,  5., 23.],\n",
      "        [31.,  3.,  1., 19.,  1.],\n",
      "        [ 0.,  2.,  0.,  0., 50.]])\n",
      "Epoch 5/10.. Train loss: 0.852.. Test loss: 1.345.. Test accuracy: 0.529\n",
      "tensor([[23.,  1., 12., 25.,  1.],\n",
      "        [ 0.,  0., 36.,  1., 13.],\n",
      "        [ 0.,  0., 40.,  4., 17.],\n",
      "        [ 3.,  0., 20., 32.,  0.],\n",
      "        [ 0.,  0.,  2.,  0., 50.]])\n",
      "Epoch 5/10.. Train loss: 0.984.. Test loss: 1.154.. Test accuracy: 0.539\n",
      "tensor([[37.,  0.,  4., 21.,  0.],\n",
      "        [ 8.,  1., 17., 12., 12.],\n",
      "        [ 2.,  0., 32.,  7., 20.],\n",
      "        [25.,  0.,  2., 28.,  0.],\n",
      "        [ 2.,  0.,  0.,  0., 50.]])\n",
      "Epoch 5/10.. Train loss: 0.792.. Test loss: 0.993.. Test accuracy: 0.582\n",
      "tensor([[35.,  2.,  5., 20.,  0.],\n",
      "        [ 3.,  8., 21.,  9.,  9.],\n",
      "        [ 1.,  1., 38.,  5., 16.],\n",
      "        [15.,  2.,  6., 32.,  0.],\n",
      "        [ 0.,  3.,  1.,  0., 48.]])\n",
      "Epoch 5/10.. Train loss: 0.832.. Test loss: 1.239.. Test accuracy: 0.531\n",
      "tensor([[36.,  0.,  6., 17.,  3.],\n",
      "        [ 3.,  1., 23.,  3., 20.],\n",
      "        [ 1.,  0., 29.,  5., 26.],\n",
      "        [20.,  0.,  6., 27.,  2.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 5/10.. Train loss: 0.695.. Test loss: 1.363.. Test accuracy: 0.531\n",
      "tensor([[38.,  1.,  8., 12.,  3.],\n",
      "        [ 3.,  2., 21.,  1., 23.],\n",
      "        [ 1.,  0., 27.,  5., 28.],\n",
      "        [20.,  2.,  4., 26.,  3.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 6/10.. Train loss: 0.782.. Test loss: 1.181.. Test accuracy: 0.596\n",
      "tensor([[29.,  1.,  4., 28.,  0.],\n",
      "        [ 3.,  9., 17., 13.,  8.],\n",
      "        [ 0.,  0., 34.,  7., 20.],\n",
      "        [ 5.,  1.,  3., 46.,  0.],\n",
      "        [ 0.,  4.,  0.,  1., 47.]])\n",
      "Epoch 6/10.. Train loss: 0.838.. Test loss: 1.288.. Test accuracy: 0.558\n",
      "tensor([[45.,  0.,  9.,  8.,  0.],\n",
      "        [ 5.,  0., 34.,  2.,  9.],\n",
      "        [ 1.,  0., 39.,  4., 17.],\n",
      "        [24.,  0.,  9., 22.,  0.],\n",
      "        [ 2.,  0.,  2.,  0., 48.]])\n",
      "Epoch 6/10.. Train loss: 0.866.. Test loss: 1.372.. Test accuracy: 0.514\n",
      "tensor([[39.,  1.,  8., 10.,  4.],\n",
      "        [ 2.,  3., 21.,  0., 24.],\n",
      "        [ 1.,  0., 29.,  3., 28.],\n",
      "        [25.,  2.,  8., 17.,  3.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 6/10.. Train loss: 0.813.. Test loss: 1.224.. Test accuracy: 0.550\n",
      "tensor([[28.,  1.,  6., 27.,  0.],\n",
      "        [ 1.,  4., 21., 12., 12.],\n",
      "        [ 0.,  0., 33.,  7., 21.],\n",
      "        [ 6.,  1.,  7., 41.,  0.],\n",
      "        [ 0.,  2.,  1.,  3., 46.]])\n",
      "Epoch 6/10.. Train loss: 0.870.. Test loss: 1.339.. Test accuracy: 0.507\n",
      "tensor([[33.,  0.,  2., 27.,  0.],\n",
      "        [ 4.,  2., 16., 18., 10.],\n",
      "        [ 3.,  0., 22., 14., 22.],\n",
      "        [15.,  0.,  2., 38.,  0.],\n",
      "        [ 0.,  0.,  0.,  7., 45.]])\n",
      "Epoch 6/10.. Train loss: 0.778.. Test loss: 1.243.. Test accuracy: 0.542\n",
      "tensor([[30.,  3.,  3., 24.,  2.],\n",
      "        [ 2.,  6., 16.,  5., 21.],\n",
      "        [ 0.,  3., 26.,  5., 27.],\n",
      "        [11.,  3.,  4., 34.,  3.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 6/10.. Train loss: 0.804.. Test loss: 1.241.. Test accuracy: 0.537\n",
      "tensor([[41.,  1.,  6., 12.,  2.],\n",
      "        [ 4.,  4., 20.,  3., 19.],\n",
      "        [ 4.,  0., 26.,  4., 27.],\n",
      "        [21.,  2.,  5., 25.,  2.],\n",
      "        [ 1.,  0.,  0.,  0., 51.]])\n",
      "Epoch 6/10.. Train loss: 0.883.. Test loss: 1.122.. Test accuracy: 0.545\n",
      "tensor([[31.,  0.,  4., 27.,  0.],\n",
      "        [ 5.,  7., 18., 15.,  5.],\n",
      "        [ 4.,  0., 32., 11., 14.],\n",
      "        [15.,  1.,  3., 36.,  0.],\n",
      "        [ 0.,  2.,  1.,  4., 45.]])\n",
      "Epoch 7/10.. Train loss: 0.746.. Test loss: 1.419.. Test accuracy: 0.549\n",
      "tensor([[30.,  0.,  4., 26.,  2.],\n",
      "        [ 2.,  1., 19.,  5., 23.],\n",
      "        [ 1.,  0., 25.,  6., 29.],\n",
      "        [ 7.,  0.,  3., 42.,  3.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 7/10.. Train loss: 0.801.. Test loss: 1.197.. Test accuracy: 0.531\n",
      "tensor([[40.,  0.,  7., 12.,  3.],\n",
      "        [ 3.,  3., 20.,  1., 23.],\n",
      "        [ 3.,  0., 28.,  4., 26.],\n",
      "        [22.,  1.,  7., 22.,  3.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 7/10.. Train loss: 0.934.. Test loss: 1.033.. Test accuracy: 0.588\n",
      "tensor([[33.,  2.,  2., 25.,  0.],\n",
      "        [ 2., 14., 12., 14.,  8.],\n",
      "        [ 3.,  3., 27., 11., 17.],\n",
      "        [ 9.,  2.,  1., 43.,  0.],\n",
      "        [ 0.,  3.,  0.,  3., 46.]])\n",
      "Epoch 7/10.. Train loss: 0.784.. Test loss: 1.136.. Test accuracy: 0.583\n",
      "tensor([[30.,  0.,  4., 28.,  0.],\n",
      "        [ 4.,  4., 20., 13.,  9.],\n",
      "        [ 1.,  0., 38., 10., 12.],\n",
      "        [ 8.,  0.,  2., 45.,  0.],\n",
      "        [ 0.,  0.,  0.,  7., 45.]])\n",
      "Epoch 7/10.. Train loss: 0.832.. Test loss: 1.207.. Test accuracy: 0.556\n",
      "tensor([[40.,  1.,  7.,  9.,  5.],\n",
      "        [ 3.,  5., 21.,  1., 20.],\n",
      "        [ 1.,  0., 33.,  3., 24.],\n",
      "        [18.,  2., 11., 22.,  2.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 7/10.. Train loss: 0.852.. Test loss: 1.175.. Test accuracy: 0.542\n",
      "tensor([[41.,  3.,  8.,  7.,  3.],\n",
      "        [ 2.,  7., 27.,  1., 13.],\n",
      "        [ 1.,  0., 35.,  3., 22.],\n",
      "        [21.,  3., 13., 17.,  1.],\n",
      "        [ 0.,  3.,  0.,  0., 49.]])\n",
      "Epoch 7/10.. Train loss: 0.813.. Test loss: 1.417.. Test accuracy: 0.494\n",
      "tensor([[38.,  0.,  0., 24.,  0.],\n",
      "        [13.,  6.,  4., 17., 10.],\n",
      "        [ 6.,  3., 10., 17., 25.],\n",
      "        [19.,  0.,  0., 36.,  0.],\n",
      "        [ 0.,  0.,  0.,  6., 46.]])\n",
      "Epoch 7/10.. Train loss: 0.711.. Test loss: 1.202.. Test accuracy: 0.549\n",
      "tensor([[32.,  1.,  8., 20.,  1.],\n",
      "        [ 1.,  5., 27.,  9.,  8.],\n",
      "        [ 0.,  0., 39.,  4., 18.],\n",
      "        [11.,  1., 16., 27.,  0.],\n",
      "        [ 0.,  1.,  1.,  2., 48.]])\n",
      "Epoch 8/10.. Train loss: 0.835.. Test loss: 1.218.. Test accuracy: 0.559\n",
      "tensor([[32.,  1.,  7., 19.,  3.],\n",
      "        [ 1.,  4., 25.,  4., 16.],\n",
      "        [ 0.,  0., 37.,  3., 21.],\n",
      "        [12.,  1., 13., 28.,  1.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 8/10.. Train loss: 0.608.. Test loss: 1.447.. Test accuracy: 0.521\n",
      "tensor([[33.,  0.,  3., 22.,  4.],\n",
      "        [ 7.,  2., 14.,  5., 22.],\n",
      "        [ 2.,  1., 23.,  8., 27.],\n",
      "        [17.,  1.,  2., 32.,  3.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 8/10.. Train loss: 0.697.. Test loss: 1.262.. Test accuracy: 0.559\n",
      "tensor([[39.,  0.,  6., 16.,  1.],\n",
      "        [ 6.,  4., 20.,  5., 15.],\n",
      "        [ 3.,  1., 33.,  4., 20.],\n",
      "        [24.,  1.,  3., 26.,  1.],\n",
      "        [ 0.,  0.,  0.,  1., 51.]])\n",
      "Epoch 8/10.. Train loss: 0.877.. Test loss: 1.187.. Test accuracy: 0.536\n",
      "tensor([[39.,  1.,  8., 14.,  0.],\n",
      "        [ 4., 10., 30.,  4.,  2.],\n",
      "        [ 5.,  4., 42.,  5.,  5.],\n",
      "        [21.,  2.,  8., 24.,  0.],\n",
      "        [ 0.,  7.,  7.,  3., 35.]])\n",
      "Epoch 8/10.. Train loss: 0.648.. Test loss: 1.228.. Test accuracy: 0.535\n",
      "tensor([[33.,  1.,  8., 18.,  2.],\n",
      "        [ 3.,  3., 22.,  1., 21.],\n",
      "        [ 0.,  2., 33.,  4., 22.],\n",
      "        [17.,  2.,  9., 25.,  2.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 8/10.. Train loss: 0.690.. Test loss: 1.473.. Test accuracy: 0.559\n",
      "tensor([[31.,  0.,  6., 23.,  2.],\n",
      "        [ 4.,  0., 22.,  3., 21.],\n",
      "        [ 1.,  0., 34.,  4., 22.],\n",
      "        [13.,  0.,  4., 36.,  2.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 8/10.. Train loss: 0.819.. Test loss: 1.122.. Test accuracy: 0.561\n",
      "tensor([[28.,  4.,  8., 22.,  0.],\n",
      "        [ 3., 12., 28.,  2.,  5.],\n",
      "        [ 0.,  4., 43.,  5.,  9.],\n",
      "        [11.,  2., 12., 30.,  0.],\n",
      "        [ 0.,  3.,  4.,  2., 43.]])\n",
      "Epoch 8/10.. Train loss: 0.975.. Test loss: 1.204.. Test accuracy: 0.534\n",
      "tensor([[58.,  2.,  2.,  0.,  0.],\n",
      "        [24., 14.,  5.,  1.,  6.],\n",
      "        [26.,  3., 22.,  3.,  7.],\n",
      "        [43.,  2.,  0., 10.,  0.],\n",
      "        [ 5.,  3.,  0.,  0., 44.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10.. Train loss: 0.773.. Test loss: 1.340.. Test accuracy: 0.545\n",
      "tensor([[26.,  1.,  3., 30.,  2.],\n",
      "        [ 8.,  3., 12.,  4., 23.],\n",
      "        [ 3.,  1., 23., 10., 24.],\n",
      "        [ 6.,  0.,  2., 45.,  2.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 9/10.. Train loss: 0.768.. Test loss: 1.182.. Test accuracy: 0.559\n",
      "tensor([[40.,  0.,  5., 16.,  1.],\n",
      "        [ 7.,  2., 15.,  5., 21.],\n",
      "        [ 4.,  0., 31.,  6., 20.],\n",
      "        [24.,  0.,  2., 28.,  1.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 9/10.. Train loss: 0.771.. Test loss: 1.047.. Test accuracy: 0.580\n",
      "tensor([[44.,  1.,  8.,  9.,  0.],\n",
      "        [ 4.,  6., 26.,  2., 12.],\n",
      "        [ 5.,  0., 38.,  6., 12.],\n",
      "        [28.,  2.,  6., 19.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 9/10.. Train loss: 0.767.. Test loss: 1.170.. Test accuracy: 0.590\n",
      "tensor([[30.,  1.,  6., 25.,  0.],\n",
      "        [ 1.,  4., 24.,  8., 13.],\n",
      "        [ 0.,  0., 36.,  7., 18.],\n",
      "        [ 7.,  1.,  7., 40.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 9/10.. Train loss: 0.827.. Test loss: 1.202.. Test accuracy: 0.547\n",
      "tensor([[42.,  0.,  2., 18.,  0.],\n",
      "        [12.,  6.,  9., 12., 11.],\n",
      "        [10.,  2., 23.,  9., 17.],\n",
      "        [24.,  2.,  1., 28.,  0.],\n",
      "        [ 1.,  0.,  0.,  0., 51.]])\n",
      "Epoch 9/10.. Train loss: 0.862.. Test loss: 1.057.. Test accuracy: 0.600\n",
      "tensor([[43.,  2.,  9.,  8.,  0.],\n",
      "        [ 2., 10., 35.,  1.,  2.],\n",
      "        [ 3.,  2., 46.,  3.,  7.],\n",
      "        [22.,  2., 12., 19.,  0.],\n",
      "        [ 1.,  2.,  1.,  0., 48.]])\n",
      "Epoch 9/10.. Train loss: 0.795.. Test loss: 1.195.. Test accuracy: 0.589\n",
      "tensor([[18.,  1.,  5., 38.,  0.],\n",
      "        [ 1.,  6., 22., 13.,  8.],\n",
      "        [ 0.,  0., 39.,  8., 14.],\n",
      "        [ 3.,  0.,  4., 48.,  0.],\n",
      "        [ 0.,  0.,  0.,  1., 51.]])\n",
      "Epoch 9/10.. Train loss: 0.819.. Test loss: 1.202.. Test accuracy: 0.538\n",
      "tensor([[34.,  1.,  4., 22.,  1.],\n",
      "        [ 9.,  5., 13.,  3., 20.],\n",
      "        [ 4.,  2., 26.,  5., 24.],\n",
      "        [21.,  2.,  2., 30.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 9/10.. Train loss: 0.816.. Test loss: 1.035.. Test accuracy: 0.588\n",
      "tensor([[48.,  3.,  5.,  6.,  0.],\n",
      "        [11., 13., 21.,  1.,  4.],\n",
      "        [12.,  3., 36.,  3.,  7.],\n",
      "        [30.,  3.,  2., 20.,  0.],\n",
      "        [ 3.,  3.,  0.,  0., 46.]])\n",
      "Epoch 10/10.. Train loss: 0.801.. Test loss: 1.175.. Test accuracy: 0.549\n",
      "tensor([[30.,  1.,  6., 24.,  1.],\n",
      "        [ 4.,  3., 20.,  2., 21.],\n",
      "        [ 1.,  0., 33.,  5., 22.],\n",
      "        [17.,  1.,  4., 32.,  1.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 10/10.. Train loss: 0.615.. Test loss: 1.257.. Test accuracy: 0.551\n",
      "tensor([[30.,  0.,  3., 28.,  1.],\n",
      "        [ 8.,  3., 11., 12., 16.],\n",
      "        [ 4.,  1., 23.,  9., 24.],\n",
      "        [ 9.,  0.,  2., 44.,  0.],\n",
      "        [ 0.,  0.,  0.,  1., 51.]])\n",
      "Epoch 10/10.. Train loss: 0.876.. Test loss: 1.077.. Test accuracy: 0.558\n",
      "tensor([[33.,  1.,  8., 20.,  0.],\n",
      "        [ 4.,  5., 30.,  5.,  6.],\n",
      "        [ 6.,  1., 40.,  5.,  9.],\n",
      "        [17.,  2.,  7., 29.,  0.],\n",
      "        [ 1.,  1.,  1.,  2., 47.]])\n",
      "Epoch 10/10.. Train loss: 0.824.. Test loss: 1.072.. Test accuracy: 0.580\n",
      "tensor([[37.,  1., 10., 14.,  0.],\n",
      "        [ 3., 10., 30.,  3.,  4.],\n",
      "        [ 2.,  2., 41.,  5., 11.],\n",
      "        [19.,  2., 11., 23.,  0.],\n",
      "        [ 1.,  1.,  1.,  0., 49.]])\n",
      "Epoch 10/10.. Train loss: 0.686.. Test loss: 1.351.. Test accuracy: 0.521\n",
      "tensor([[39.,  0.,  0., 21.,  2.],\n",
      "        [11.,  7.,  5.,  9., 18.],\n",
      "        [ 6.,  4., 13., 14., 24.],\n",
      "        [20.,  2.,  1., 31.,  1.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 10/10.. Train loss: 0.968.. Test loss: 1.308.. Test accuracy: 0.535\n",
      "tensor([[38.,  0.,  6., 15.,  3.],\n",
      "        [ 4.,  2., 19.,  2., 23.],\n",
      "        [ 1.,  0., 31.,  4., 25.],\n",
      "        [23.,  2.,  4., 23.,  3.],\n",
      "        [ 0.,  0.,  0.,  0., 52.]])\n",
      "Epoch 10/10.. Train loss: 0.698.. Test loss: 1.128.. Test accuracy: 0.571\n",
      "tensor([[38.,  1., 16.,  7.,  0.],\n",
      "        [ 2.,  8., 33.,  1.,  6.],\n",
      "        [ 0.,  1., 46.,  3., 11.],\n",
      "        [19.,  2., 18., 15.,  1.],\n",
      "        [ 1.,  1.,  0.,  0., 50.]])\n",
      "Epoch 10/10.. Train loss: 0.739.. Test loss: 1.061.. Test accuracy: 0.557\n",
      "tensor([[35.,  1.,  4., 22.,  0.],\n",
      "        [ 9., 14., 11., 11.,  5.],\n",
      "        [ 7.,  4., 30.,  8., 12.],\n",
      "        [21.,  3.,  2., 29.,  0.],\n",
      "        [ 0.,  2.,  0.,  4., 46.]])\n",
      "Epoch 10/10.. Train loss: 0.852.. Test loss: 1.250.. Test accuracy: 0.541\n",
      "tensor([[39.,  0.,  3., 19.,  1.],\n",
      "        [10.,  2., 14., 12., 12.],\n",
      "        [ 7.,  1., 26.,  8., 19.],\n",
      "        [22.,  0.,  3., 30.,  0.],\n",
      "        [ 0.,  0.,  0.,  1., 51.]])\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 5\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        steps += 1\n",
    "        # Move input and label tensors to the default device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            \n",
    "            confusion_matrix = torch.zeros(num_classes, num_classes)\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    \n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    # Calculate accuracy\n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "                    \n",
    "                    for t, p in zip(labels.view(-1), top_class.view(-1)):\n",
    "                            confusion_matrix[t.long(), p.long()] += 1\n",
    "                    \n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "            print(confusion_matrix)\n",
    "            running_loss = 0\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e86066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ec1b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckpt(ckpt_path):\n",
    "    ckpt = torch.load(ckpt_path)\n",
    "\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(512, 400)),\n",
    "                      ('relu', nn.ReLU()),\n",
    "                      ('fc2', nn.Linear(400, 5)),\n",
    "                      ('output', nn.LogSoftmax(dim=1))\n",
    "                      ]))\n",
    "\n",
    "    model.load_state_dict(ckpt, strict=False)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a5268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = 'checkpoint1.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc31c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_ckpt(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ca8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an torch Tensor\n",
    "    '''\n",
    "    im = PIL.Image.open(image)\n",
    "    if im.mode != 'RGB':\n",
    "        im = im.convert('RGB')\n",
    "    return test_transforms(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797e3b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model):\n",
    "    # Predict the class of an image using a trained deep learning model.\n",
    "    model.eval()\n",
    "    img_pros = process_image(image_path)\n",
    "    img_pros = img_pros.view(1,5,224,224)\n",
    "    with torch.no_grad():\n",
    "        output = model(img_pros)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3c3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe94003",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '.png'\n",
    "log_ps = predict(img_path, model)\n",
    "cls_score = int(torch.argmax(torch.exp(log_ps)))\n",
    "if cls_score == 0:\n",
    "    print('cercospora')\n",
    "elif cls_score == 1:\n",
    "    print('healthy')\n",
    "elif cls_score == 2:\n",
    "    print('mites_and_trips')\n",
    "elif cls_score == 3:\n",
    "    print('nutritional defeciency')\n",
    "else:\n",
    "    print('powdery mildew')\n",
    "PIL.Image.open(img_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
